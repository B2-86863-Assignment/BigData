1. Calculate hottest and coolest month from ncdc data.

CREATE TABLE ncdc_month_staging(
yr SMALLINT,
mnth SMALLINT,
tmp SMALLINT,
quality SMALLINT
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
WITH SERDEPROPERTIES (
  "input.regex" = "^.{15}([0-9]{4})([0-9]{2}).{66}([-\+][0-9]{4})([0-9]).*$"
)
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '/home/aditya/Desktop/Sunbeam/BigData/data/ncdc'
INTO TABLE ncdc_month_staging;


(SELECT mnth, AVG(tmp) avg_tmp FROM ncdc_month_staging WHERE tmp != 9999
AND quality IN (0,1,2,4,5,9)
GROUP BY mnth
ORDER BY avg_tmp 
LIMIT 1)
UNION
(SELECT mnth, AVG(tmp) avg_tmp FROM ncdc_month_staging WHERE tmp != 9999
AND quality IN (0,1,2,4,5,9)
GROUP BY mnth
ORDER BY avg_tmp DESC
LIMIT 1);

+-----------+---------------------+
| _u1.mnth  |     _u1.avg_tmp     |
+-----------+---------------------+
| 2         | -75.16562866684718  |
| 7         | 160.3485770685968   |
+-----------+---------------------+


2. Execute following queries on "emp" and "dept" dataset.
    1. Create table "emp_staging" and load data from emp.csv in it.
    2. Create table "dept_staging" and load data from dept.csv in it.
    3. Display dept name and number of emps in each dept.

SELECT d.dname,COUNT(e.empno) FROM dept_staging d LEFT JOIN emp_staging e ON e.deptno=d.deptno GROUP BY d.dname;
+-------------+------+
|   d.dname   | _c1  |
+-------------+------+
| ACCOUNTING  | 3    |
| OPERATIONS  | 0    |
| RESEARCH    | 5    |
| SALES       | 6    |
+-------------+------+

    4. Display emp name and his dept name.

SELECT e.ename,d.dname FROM dept_staging d LEFT JOIN emp_staging e ON e.deptno=d.deptno;
+----------+-------------+
| e.ename  |   d.dname   |
+----------+-------------+
| CLARK    | ACCOUNTING  |
| KING     | ACCOUNTING  |
| MILLER   | ACCOUNTING  |
| SMITH    | RESEARCH    |
| JONES    | RESEARCH    |
| SCOTT    | RESEARCH    |
| ADAMS    | RESEARCH    |
| FORD     | RESEARCH    |
| ALLEN    | SALES       |
| WARD     | SALES       |
| MARTIN   | SALES       |
| BLAKE    | SALES       |
| TURNER   | SALES       |
| JAMES    | SALES       |
| NULL     | OPERATIONS  |
+----------+-------------+


    5. Display all emps (name, job, deptno) with their manager (name, job, deptno), who are not in their department.

SELECT e1.ename,e2.ename,e1.job,e1.deptno FROM emp_staging e1 LEFT JOIN emp_staging e2 ON e2.empno=e1.mgr INNER JOIN 
dept_staging d ON d.deptno=e1.deptno WHERE e2.deptno!= e1.deptno;
+-----------+-----------+----------+------------+
| e1.ename  | e2.ename  |  e1.job  | e1.deptno  |
+-----------+-----------+----------+------------+
| JONES     | KING      | MANAGER  | 20         |
| BLAKE     | KING      | MANAGER  | 30         |
+-----------+-----------+----------+------------+

    6. Display all manager names with list of all dept names (where they can work).

SELECT DISTINCT e2.ename,d.dname FROM emp_staging e1 INNER JOIN emp_staging e2 ON e2.empno=e1.mgr INNER JOIN 
dept_staging d ON d.deptno=e1.deptno;
+-----------+-------------+
| e2.ename  |   d.dname   |
+-----------+-------------+
| BLAKE     | SALES       |
| CLARK     | ACCOUNTING  |
| FORD      | RESEARCH    |
| JONES     | RESEARCH    |
| KING      | ACCOUNTING  |
| KING      | RESEARCH    |
| KING      | SALES       |
| SCOTT     | RESEARCH    |
+-----------+-------------+


    8. Display job-wise total salary along with total salary of all employees.
SELECT job,SUM(sal) total_sal FROM emp_staging group by job WITH ROLLUP;
+------------+------------+
|    job     | total_sal  |
+------------+------------+
| NULL       | 29025.0    |
| ANALYST    | 6000.0     |
| CLERK      | 4150.0     |
| MANAGER    | 8275.0     |
| PRESIDENT  | 5000.0     |
| SALESMAN   | 5600.0     |
+------------+------------+


    9. Display dept-wise total salary along with total salary of all employees.

SELECT deptno,SUM(sal) total_sal FROM emp_staging group by deptno WITH ROLLUP;
+---------+------------+
| deptno  | total_sal  |
+---------+------------+
| NULL    | 29025.0    |
| 10      | 8750.0     |
| 20      | 10875.0    |
| 30      | 9400.0     |
+---------+------------+

    10. Display per dept job-wise total salary along with total salary of all employees.

SELECT job,deptno,SUM(sal) total_sal FROM emp_staging group by job,deptno WITH ROLLUP;
+------------+---------+------------+
|    job     | deptno  | total_sal  |
+------------+---------+------------+
| NULL       | NULL    | 29025.0    |
| ANALYST    | NULL    | 6000.0     |
| ANALYST    | 20      | 6000.0     |
| CLERK      | NULL    | 4150.0     |
| CLERK      | 10      | 1300.0     |
| CLERK      | 20      | 1900.0     |
| CLERK      | 30      | 950.0      |
| MANAGER    | NULL    | 8275.0     |
| MANAGER    | 10      | 2450.0     |
| MANAGER    | 20      | 2975.0     |
| MANAGER    | 30      | 2850.0     |
| PRESIDENT  | NULL    | 5000.0     |
| PRESIDENT  | 10      | 5000.0     |
| SALESMAN   | NULL    | 5600.0     |
| SALESMAN   | 30      | 5600.0     |
+------------+---------+------------+
15 rows selected (19.517 seconds)


    11. Display number of employees recruited per year in descending order of employee count.

SELECT YEAR(HIRE) yr, COUNT(empno) FROM emp_staging GROUP BY YEAR(HIRE);

    12. Display unique job roles who gets commission.

+-------+------+
|  yr   | _c1  |
+-------+------+
| 1980  | 1    |
| 1981  | 10   |
| 1982  | 2    |
| 1983  | 1    |
+-------+------+


    13. Display dept name in which there is no employee (using sub-query).

SELECT DISTINCT dname FROM dept_staging d WHERE d.deptno NOT IN (SELECT DISTINCT e.deptno FROM emp_staging e WHERE e.deptno=d.deptno);
+-------------+
|    dname    |
+-------------+
| OPERATIONS  |
+-------------+

    14. Display emp-name, dept-name, salary, total salary of that dept (using sub-query).

SELECT e.ename,d.dname,e.sal, (SELECT SUM(sal) FROM emp_staging) total FROM emp_staging e INNER JOIN dept_staging d ON d.deptno=e.deptno;
+----------+-------------+---------+----------+
| e.ename  |   d.dname   |  e.sal  |  total   |
+----------+-------------+---------+----------+
| SMITH    | RESEARCH    | 800.0   | 29025.0  |
| ALLEN    | SALES       | 1600.0  | 29025.0  |
| WARD     | SALES       | 1250.0  | 29025.0  |
| JONES    | RESEARCH    | 2975.0  | 29025.0  |
| MARTIN   | SALES       | 1250.0  | 29025.0  |
| BLAKE    | SALES       | 2850.0  | 29025.0  |
| CLARK    | ACCOUNTING  | 2450.0  | 29025.0  |
| SCOTT    | RESEARCH    | 3000.0  | 29025.0  |
| KING     | ACCOUNTING  | 5000.0  | 29025.0  |
| TURNER   | SALES       | 1500.0  | 29025.0  |
| ADAMS    | RESEARCH    | 1100.0  | 29025.0  |
| JAMES    | SALES       | 950.0   | 29025.0  |
| FORD     | RESEARCH    | 3000.0  | 29025.0  |
| MILLER   | ACCOUNTING  | 1300.0  | 29025.0  |
+----------+-------------+---------+----------+



    15. Display all managers and presidents along with number of (immediate) subbordinates.

SELECT e2.ename,COUNT(e2.ename) cnt FROM emp_staging e1 INNER JOIN emp_staging e2 ON e2.empno =e1.mgr WHERE e2.job IN ("MANAGER","PRESIDENT")
GROUP BY e2.ename ;

+-----------+------+
| e2.ename  | cnt  |
+-----------+------+
| BLAKE     | 5    |
| CLARK     | 1    |
| JONES     | 2    |
| KING      | 3    |
+-----------+------+


3. Execute following queries for books.csv dataset.
    1. Create table "books_staging" and load books.csv in it.
CREATE TABLE books_staging(
id INT,
title STRING,
author STRING,
subject STRING,
price DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '/home/aditya/Desktop/Sunbeam/BigData/data/books.csv' INTO TABLE books_staging;

    2. Create table "books_orc" as transactional table.

CREATE TABLE books_orc(
id INT,
title STRING,
author STRING,
subject STRING,
price DOUBLE
)
STORED AS ORC
TBLPROPERTIES('transactional'='true');

INSERT INTO books_orc
SELECT * FROM books_staging;

    
    3. Create a materialized view for summary -- Subjectwise average book price.

CREATE MATERIALIZED VIEW mv_avg_books AS 
SELECT subject, avg(price) avg_sub FROM books_orc GROUP BY subject;

    4. Display a report that shows subject and average price in descending order -- on materialized view.

SELECT subject , avg_sub FROM mv_avg_books ORDER BY avg_sub DESC;
+--------------------+--------------------+
|      subject       |      avg_sub       |
+--------------------+--------------------+
| C++ Programming    | 675.214            |
| Java Programming   | 519.67             |
| Operating Systems  | 447.3836666666666  |
| C Programming      | 242.20275          |
+--------------------+--------------------+

    5. Create a new file newbooks.csv.
        ```
        20,Atlas Shrugged,Ayn Rand,Novel,723.90
        21,The Fountainhead,Ayn Rand,Novel,923.80
        22,The Archer,Paulo Cohelo,Novel,623.94
        23,The Alchemist,Paulo Cohelo,Novel,634.80
        ```


    6. Upload the file newbooks.csv into books_staging.
    7. Insert "new" records from books_staging into books_orc.
    8. Display a report that shows subject and average price in descending order -- on materialized view. -- Are new books visible in report?
    9. Rebuild the materialized view.
    10. Display a report that shows subject and average price in descending order -- on materialized view. -- Are new books visible in report?
    11. Increase price of all Java books by 10% in books_orc.
    12. Rebuild the materialized view.
    13. Display a report that shows subject and average price in descending order -- on materialized view. -- Are new price changes visible in report?
    14. Delete all Java books.
    15. Rebuild the materialized view.
    16. Display a report that shows subject and average price in descending order -- on materialized view. -- Are new price changes visible in report?
4. Upload busstops.json data into HDFS directory. Then create hive external table to fetch data using JsonSerDe.
    ```
    {"_id":{"$oid":"5a0720b478597fc11004d951"},"stop":"Non-BRTS","code":"103B-D-04","seq":4.0,"stage":1.0,"name":"Aranyeshwar Corner","location":{"type":"Point","coordinates":[73.857675,18.486381]}}
    ```
    ``` 
    location STRUCT<type:STRING, coordinates:ARRAY<DOUBLE>>
    ```
    ```
    When column-name have special charatcters like _ or $, they should be encapsulated in `back-quotes`.
    ```
5. Implement Movie recommendation system.
    * Example Input Data
        ```
        userId,movieId,rating,rtime
        17,70,3,0
        35,21,1,0
        49,19,2,0
        49,21,1,0
        49,70,4,0
        87,19,1,0
        87,21,2,0
        98,19,2,0
        ```
    * Create pairs of movies rated by same user.
        ```
        userId,movie1,rating1,movie2,rating2
        49,21,1.0,70,4.0
        49,19,2.0,21,1.0
        49,19,2.0,70,4.0
        87,19,1.0,21,2.0
        ```
    * Create correlation table.
        ```
        movie1,movie2,cnt,cor
        19,21,2,-1.0
        19,70,1,0.0
        21,70,1,0.0
        ```
    * Predict Similar movies for given movie Id. Get the recommended movies titles from movies table.
    * Hints
        * Start with above small data tables to test accuracy of the steps.
        * You will need to create new intermediate tables to store results of earlier queries.
        * For main data use ORC format to speed-up the queries.
        * You may need to change reducer tasks memory for quicker execution and avoid OutOfMemory errors.
            * SET mapreduce.reduce.memory.mb = 4096;
            * SET mapreduce.reduce.java.opts = -Xmx4096m;
